# 자바 개발자를 위한 97가지 제안

전세계 유명 자바 개발자들에게 자바에 대한 팁을 얻을 수 있다면 얼마나 유용할까? 
그 해답을 책에서 찾았다.
[자바 개발자를 위한 97가지 제안(97 Things Every Java Programmer Should Know)](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=258021255) 이 바로 그 책이다.
책의 내용중 감명받은 일부분을 간추려 요약해 보았다.



## 컨테이너를 제대로 이해하자 (David Delabassee)

오래된 JVM을 도커 컨테이너에서 실행하면 안된다.

레거시 자바 애플리케이션을 레거시 자바 가상 머신(JVM) 상에 있는 그대로 컨테이너화하지마라.

레거시 자바 애플리케이션과 그에 의존하는 환경을 컨테이너화하면 오래된 애플리케이션도 최신 인프라에서 구동할 수 있는데 왜 사용하지 않아야 되는가?

**JVM의 어거노믹스(ergonomics, 인간공학)때문이다.** 어거노믹스란 JVM과 GC가 애플리케이션 성능 향상을 위해 자가 학습 하는 프로세스를 말한다. ([어거노믹스에 대한 오라클 공식 문서](https://docs.oracle.com/en/java/javase/11/gctuning/ergonomics.html#GUID-DB4CAE94-2041-4A16-90EC-6AE3D91EC1F1))

JVM 어거노믹스는 어떻게 자가 학습을 한다는 말인가?

- CPU와 가용 메모리를 기준으로 JVM을 직접 튜닝한다.
- JVM은 이 두가지 지표를 이용해 어떤 가비지 컬렉터를 이용할지, 가바지 컬렉터를 어떻게 설정할지, 힙 메모리 크기는 얼마로 할지, ForkJoinPool 크기는 얼마로 할지를 결정한다.

JDK 8의 191 업데이트는 리눅스 도커 컨테이너 지원이 추가되어 있다.
JVM은 리눅스 croups를 이용해 자신이 실행 중인 컨테이너에 할당된 리소스에 대한 지표를 측정한다.
(Croups이란 *컨트롤 그룹 (control group)*이라는 커널 기능으로서, Cgroup을 통해 사용자는 CPU 시간, 시스템 메모리, 네트워크 대역폭과 같은 자원이나 이러한 자원의 조합을 시스템에서 실행 중인 사용자 정의 작업 그룹 (프로세스) 간에 할당할 수 있다. )

하지만 JDK 8u191 이전 버전의 JVM은 자신이 컨테이너 안에 있다는 것을 모른다. 
따라서, 컨테이너가 아닌 호스트 OS의 지표를 측정하려 한다.
만약 호스트 OS 지표를 측정하려 한다면, **JVM이 잘못된 지표를 스스로 튜닝하려 시도할 것이다.**
예를 들어, 컨테이너가 가용한 리소스보다 많은 리소스를 소비하여 호스트 OS가 컨테이너를 강제 종료하는 상황이 존재할 수 있다.

가장 이상적인 해결책은 JDK11 이후의 버전을 사용하는 것이다.



## 행위를 구현하는 것은 쉽지만, 상태를 관리하는 것은 어렵다 (Edson Yanaga)

우리가 객체지향 프로그래밍을 배울 때 가장 먼저 배우는 개념은 다형성, 상속, 캡슐화 일것이다.
이 세 가지 개념 중 가장 덜 중요해보이지만 가장 필수적인 것은 캡슐화다.
캡슐화를 지키면서 코딩을 해봐라, 객체가 해야할 행동이 바뀌어도 상대적으로 더 적은 코드만 수정할 것이다.
즉, **상태를 내면화하여 다른 컴포넌트로부터 숨기면 안전하게 디자인된 API로만 상태를 변경할 수 있기 때문이다.**

행위란 거칠게 말해 객체의 메서드를 의미한다. 상태란 객체에 정의된 필드의 데이터다.
행위에 의해 발생한 버그는 비교적 구분하고 추적하기 쉽다.
반면, 널 값이 되거나 음수의 값을 갖는 등 시스템이 가지면 안되는 상태가 되면 그 문제점은 파악하기 쉽지 않다.

이러한 상태로 인한 문제를 해결하려면 어떻게 해야할까?
불변성(immutability)가 그 해법 중 하나다.
Setter와 같은 상태를 변경하는 메서드를 없애버리고 객체를 생성하는 시점에만 상태의 무결성을 따지는 것이다.
자바에서는 팩토리 메서드와 빌더패턴을 잘 활용한다면 불변성을 지킬 수 있다.



## JVM의 동시성 (Mario Fusco)

원시 스레드(raw thread)를 이용한 25년전 자바를 만들 때의 하드웨어는 지금과 다르다. 
이것이 지금에 이르러서 큰 차이점을 일으킨다.
어떤 차이점일까?
최근 병렬 애플리케이션의 수요는 보편적이다. 

자바의 메모리 모델을 이해하는 것은 어려우며,
공유할 수 있는 가변 상태를 이용해 통신하는 스레드는 병렬 프로그래밍에 어울리지 않다.
또한, 메모리 접근을 동기화하기 위해 투자하는 노력 조차 일이된다.

그렇다면 어떻게 공유 메모리 제한을 극복해야 하는가?
**Lock 대신 분산 큐(Distributed Queue)를 사용하라.**
즉, 메모리를 공유하지 말고 메시지를 전달하라.

JVM의 언어 모델들은 어떻게 동시성을 제어할 할까?

아카 또는 스칼라는 액터 모델을 사용하여 액터 간의 메시지를 주고 받아서 마치 큐를 사용하는 것과 같다.

클로저는 내장된 트랜잭션 메모리를 사용하여 JVM 힙 메모리를 트랜잭션을 지원하는 데이터 셋으로 바꾼다.

자바 8의 람다(lambda)는 불변성과 참조 투명성 같은 함수형 프로그래밍 특성을 자바에 녹여냈다.
액터 모델은 공유를 금지하여 상태 변경을 줄이지만, 함수형 프로그래밍은 가변성을 금지하여 상태 공유를 허락한다.
함수형 프로그래밍의 장점은 부수효과(side-effect) 없는 함수로 병렬 코드를 쉽게 작성가능 하다.
하지만, 함수형 프로래밍은 일반적으로 명령형 프로그램보다 시간효율이 떨어지며, 가비지 컬렉터에 더 많은 부담을 줄 수 있다.

동시성을 해결하기 위한 은탄환은 없다. 각자의 장단점을 이해하고 상황에 적합한 것을 선택하는 것이 중요하다.



## CountDownLatch 친구인가 적인가? (Alexy Soshin)

여러 동시성 작업을 실행하도록 하고 이 작업들 모두가 끝나기 까지 기다려야만한다면 어떻게 구현해야 할까?

ExecutorService 클래스라면 간단하다.

```java
ExecutorService pool = Executors.newFixedThreadPool(8);
Future<?> future = pool.submit(() -> { 
  //태스트 실행 
})
```

그런데 이 태스크가 끝날때까지 기다리려면 어떻게 해야하는가? 

CountDownLatch를 각 작업이 완료되는 시점에 메서드를 호출하도록 한다.

```java
int tasks = 16; // 작업의 개수
CountDownLatch latch = new CountDownLatch(tasks);
for (int i = 0; i < tasks; i++) {
  Future<?> future = pool.submit(() -> {
    try {
      // 해야할 일을 처리한다.
    } finally {
      latch.countDown();
    }
  })
}
if (!latch.await(2, TimeUnit.SECONDS)) {
  //타임아웃을 처리한다.
}
```

이 코드에서 반드시 지켜야할 점이 있다.

1. finally 블록에서 반드시 CountDownLatch를 릴리즈해야 한다. 예외가 발생한다면 영원히 작업을 기다릴 것이다.
2. await 메서드에 타임아웃 기간을 정하라. 1번의 CountDownLatch를 finally에서 릴리즈하는 것을 2차로 막을 수 있다.
3. 메서드의 리턴 값을 확인하라. 이 메서드는 타임아웃이 나면 `false`를 반환한다. 지정한 시간 내에 작업이 완료되면, `true`를 반환한다.



CountDownLatch는 유용하지만 사용하지 않아야할 때가 있다.

코틀린의 코루틴(Coroutine), Vert.x 또는 스프링 웹플럭스(WebFlux) 같은 동시성 라이브러리나 프레임워크의 코드에 사용하면 안된다.

왜냐하면, CountDownLatch 클래스가 현재 스레드를 블록하기 때문이다. 

즉, 이미 프레임워크 수준에서 동시성을 관리한다면 다른 동시성 방법을 혼합하는 것은 좋지 않다.



## 가비지 컬렉션은 나의 친구 (Holly Cummins)

불쌍한 가비지 컬렉션. 비난만 받고 대접은 받지 못하는 안타까운 자바 영웅 중 하나다.
자바가 가비지 컬렉션을 도입하기 전에는 어떻게 메모리를 관리해야했을까?

자신이 할당(allocate)한 모든 메모리를 손수 추적하여 더 사용하지 않게되었을 때 이를 해제(deallocate)해야 했다.
아무리 숙련된 개발자라고 해도 메모리를 손수해제하는 것은 메모리 누수(메모리 해제가 너무 늦은 경우)나 크래시(메모리 해제를 너무 빨리한 경우)의 원인이 된다.

GC는 필요에 의해 지불해야 하는 비용이다. 

**현대의 가비지 컬렉션은 메모리를 할당하거나 해제하는 것보다 더 빠르다. 
또한, GC가 실행되는 와중에도 GC 속도를 높일 수 있다.**
이게 어떻게 가능할까?

간단하게 설명하자면, 가비지 컬렉터는 메모리 할당과 동시에 메모리상 객체 재정렬도 실행한다.
좋은 메모리 관리 알고리즘은 단편화와 경합을 줄여 효과적으로 메모리를 할당하는 것이다.
객체를 재정렬하여 처리량을 향상하고 응답 시간을 줄일 수 있다.

도대체  메모리상 객체 위치가 애플리케이션 성능에 어떻게 영향을 준다는 말인가?
그 질문에 앞서 프로그램 실행 시간 대부분을 차지하는 것이 무엇인지 아는가?
대부분 메모리 접근을 기다리는 시간이다. 
따라서, 현대의 컴퓨터는 캐시를 사용하는데, 프로세서의 캐시에서 객체를 불러오는 동시에 이웃한 데이터도 함께 가져온다.
이렇게 동시에 사용하는 객체를 메모리 상에 서로 가깝게 배치하는 것을 **객체 지역성(object locality)**라고 한다.

GC 컬렉터에는 크게 두 가지 컬렉터가 있다. 

- Stop-the-world 컬렉터는 모든 프로그램 동작을 멈추는 이른바 stop-the-world 상태를 만들어버린다.
  하지만, 모든 프로그램은 동작을 멈추므로 안전히 메모리를 수집한다.
- 동시(concurrent) 컬렉터는 수집 작업을 애플리케이션 스레드에 넘기므로 멈춤은 발생하지 않는다.
  대신, 각 스레드에서 약간의 지연을 감수해야 한다.
- 어떤 것을 언제 사용해야 할까? 동시 컬렉터의 경우 마우스를 움직이는 GUI와 같이 멈춤 현상이 없는 애플리케이션에 더 적합하다.



GC가 소비하는 시간을 너무 세세하게 최적화할 필요는 없다.
GC가 소비하는 시간은 결국 프로그램의 속도에 도움이 되기 때문이다.