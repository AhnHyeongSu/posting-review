# 1. 메모리 관리 배경

### 메모리 계층 구조

![image](https://user-images.githubusercontent.com/38436013/128971630-c80eb39d-d0d4-41e1-8824-915a9bcc2731.png)

HW가 관리(CPU) : 레지스터, 캐시 !

SW가 관리(OS) : 메인메모리, 보조기억장치

속도 : (빠름) 레지스터 > 캐시 > 메모리 > 하드디스크 (느림) , 용량은 속도의 반대순서다. 

> 레지스터와 캐시는 CPU 내부에 존재하므로 CPU가 빠르게 접근한다. 메모리와 하드디스크는 CPU외부에 있으므로 CPU가 느리게 접근한다.
>
> 하드디스크는 CPU가 직접 접근할 방법이 없으므로, 하드디스크 데이터를 메모리로 이동시킨후, CPU는 메모리로 접근해야 한다.

### 메모리에 프로그램 할당 과정

프로그램이 로드되는 장소는 메모리(RAM)이고, 프로그램이 저장되어 있는 장소는 하드디스크다.

저장된 프로그램을 실행하기 위해서는 하드디스크에서 메모리로 프로그램이 옮겨져야 한다.

다시 말해 프로세스(프로그램)가 메모리 상에서 독립된 공간을 확보해야 한다.

#### 1. 프로그램 빌드 과정

<img src="https://user-images.githubusercontent.com/38436013/129016105-346be710-22fa-4cdb-9f5e-64daa0b3ce09.png" alt="image" style="zoom:80%;" />

1. 소스파일을 컴파일러가 읽어서 바이너리 파일(오브젝트 파일)을 생성한다.
2. 링크 단계에서 디스크에서 개발자가 추가한 라이브러리 파일을 찾아 추가하여 실행파일을 만든다.
3. 이 프로그램을 실행하면 로더에 의해 메인 메모리에 할당된다.

### 주소 할당, 주소 바인딩

주소는 논리 주소와 물리 주소가 있다.

논리 주소는 **cpu가 생성하는 주소**로, 프로세스마다 독립적으로 가지는 공간이다.

물리 주소는 **메모리가 취급하는 주소**로 메모리에 실제 올라가는 위치를 말한다.

#### 주소 바인딩에는 3가지가 있다.

1. 컴파일 시간 바인딩(compile time) : 소스코드를 컴파일 하는 그 순간에  메모리 주소를 부여받는 것을 컴파일 시간 바인딩이라고 한다. 소스코드를 컴파일 하게 되면 실행파일이 되고 이는 cpu가 아는 논리 주소가 된다. (주소 위치를 변경하고 싶다면 다시 컴파일)
2. 적재 시간 바인딩(load time) : 소스코드를 컴파일 해서 목적파일을 만들고 링커를 통해 실행파일을 만들었다고 했을 때, 이 실행파일을 실행하는 순간에 물리적 주소를 부여 받는 것이 적재 시간 바인딩이다.(주소 위치를 변경하고 싶다면 다시 실행)
3. 실행 시간 바인딩(run time) : 적재시간 바인딩과 마찬가지로 실행 순간에 메모리 주소를 부여받는다. 실행 시간 바인딩은 실행 중에도 해당 프로세스의 물리 주소가 변경될 수 있다. 스왑 인, 아웃 되거나 프로세스가 내려갔다가 다시 오거나 하는 경우에 동일한 주소로 가는 것이 아니라 새로운 주소로 갈 수 있는 것이다. 근데 이 친구는 하드웨어적인 지원이 필요하다.(MMU) 왜냐하면 어느 주소로 이동했을 수도 있으니까 그 때마다 바인딩 체크를 해야한다. (굉장히 유동적이다, 현 시점에 사용)

#### 2. 실제로 메모리에 올리는 과정

프로그램을 메모리에 올리려면 메모리 주소를 알아야 한다.

주소 정보는 CPU에 있고, 프로그램은 메모리에 있기 때문에 CPU는 메모리에 주소를 요청하고, 메모리는 CPU에 데이터를 반환해준다.

CPU와 메모리 사이에 양방향 통신을 가능하게 해주는 것이 MMU이다.

![image](https://user-images.githubusercontent.com/38436013/128975528-81bea6a0-375d-4924-8369-255f33c29741.png)

MMU (Memory Management Unit, MMU) 의 역할

주소 번역과 메모리 보호가 있다. 동적으로 논리 주소에 재배치 되는 레지스터 값을 더하여 주소를 변환한다.

1. 재배치 레지스터 : CPU에서 사용한 주소와 메모리에 할당된 주소가 달라도 MMU를 거치면 **주소 번역**을 하여 정상 수행이 가능하다.  프로그램의 실제 메모리 주소는 CPU에 영향을 주지 않는다.

   > 프로그램이 메인 메모리 500번지에 할당되어 재배치 레지스터값이 500으로 설정되었다면, CPU에서 프로그램의 0번지를 사용할 때 MMU를 통과하면 재배치 레지스터에 의해 500번지로 변경된다. 그 결과 CPU는 0번지를 사용하는 것으로 알고 있지만, 실제 메모리에서는 MMU에 의해 500번지를 사용하고 있는 것이다.

2. base, limit 레지스터 : **메모리 보호**를 위해  CPU 주소가 base나 limit 범위를 벗어나면, 인터럽트가 발생하여 그 프로그램을 강제로 종료

CPU에서 사용하는 주소는 **논리 주소(logical address)**라고 하고,  메모리가 사용하는 주소는 **물리 주소(physical address)**라고 한다.

# 2. 메모리 관리 기법

물리 메모리 공간이 제한되어 있으므로, 효율적으로 메모리에 할당하자!

- **스와핑 (Swapping)**

- **연속 메모리 할당 (Contiguous memory allocation)**

- 페이징 (Paging)

- 세그멘테이션 (Segmentation)

### 1. 스와핑

부족한 메모리 공간을 좀 더 효율적으로 관리하려는 메모리 관리 기법

Swapping은 메모리에 적재되어 있는 프로세스 중에서 오랫동안 사용하지 않은 프로세스를 프로세스 이미지 형태로 만든 후 하드디스크에 내려보낸다. 메모리에서 하드디스크로 가는 것을 **swap-out**, 다시 하드디스크에서 메모리로 가는 것을 **swap-in**이라고 한다.

### 2. 연속 메모리 할당

#### 메모리 단편화

프로세스들이 메모리에 생성, 종료되는 일이 반복되면, 프로세스들이 차지하는 메모리 틈 사이에 홀이 생긴다. 이것을 단편화라고 한다.

![image](https://user-images.githubusercontent.com/38436013/128981671-0b43bd16-2558-435d-8695-3c7643f49571.png)

- 내부 단편화 : 할당된 프로그램의 크기가 메모리의 크기보다 작아서, 사용하지 않는 빈 공간이 생기는 현상, 예를 들어 메모리 공간 1000B에 프로세스 999B를 할당하는 경우 1B가 남음
- 외부 단편화 : 하나의 프로세스를 흩어진 홀들에 나누어 할당할 수 없는 현상

#### 외부 단편화 해결 방법1 - 연속 메모리 할당

First-fit, Best-fit, Worst-fit

- **First-fit(최초 적합)**: 최초 적합은 할당할 프로세스 크기보다 크거나 같은 hole을 탐색하는 순서 중에서 가장 먼저 찾은 hole에 프로세스를 할당
- **Best-fit(최적 적합)**: 최적 적합은 할당할 프로세스 크기와 hole 크기의 차이가 가장 작은 hole에 프로세스를 할당.(hole크기는 프로세스 크기보다 반드시 커야 한다.)
- **Worst-fit(최악 적합)**: 최적 적합과 반대로, 할당할 프로세스 크기와 hole 크기의 차이가 가장 큰 hole에 프로세스를 할당

속도면에서는 first-fit이 가장 빠르다. 메모리 이용률면에서는 first-fit, best-fit이 비슷한 성능을 낸다고 알려져있다. 하지만 여러 실험을 통해 best-fit을 사용하더라도 외부 단편화로 인해 **전체 메모리의 1/3 정도를 낭비**한다고 한다.

#### 외부 단편화 해결 방법2 

연속 메모리 할당으로 해결 되지 않는 외부 단편화 문제는 메모리압축, 페이징, 세그멘테이션으로 해결한다.

**압축**

외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유공간을 확보하는 방법론 이지만, 작업효율이 좋지 않다.

### 3. 페이징 

- 페이지 단위의 논리 - 물리 주소 관리 기법

- **프로세스가 사용하는 메모리 공간을 잘게 나누어서,  실제 메모리에 비연속적으로 할당하는 메모리 관리 기법**

- **하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 기법!!**  -> 외부 단편화 없다

외부 단편화의 압축 문제를 해소하기 위해 생긴 방법론으로, 물리 메모리는 Frame 이라는 고정 크기로 분리되어 있고, 논리 메모리(프로세스가 점유하는)는 페이지라 불리는 고정 크기의 블록으로 분리된다.

![image](https://user-images.githubusercontent.com/38436013/128986032-f52b7814-1c6b-42bc-b7e1-dc10cc9ffbec.png)

단점 : 페이지 크기보다 작은 메모리를 요청하는 경우에 발생 -> 내부 단편화 

예를들어 페이지 크기가 4KB인데 10KB의 메모리를 필요하는 프로세스는 이 페이지가 2개 + 2KB할당되는 것이 아니라 3개가 할당되어야지만 10KB메모리를 쓸 수 있다. 마지막으로 할당된 페이지는 실제로 프로세스가 2KB 만 사용하고 나머지 2KB는 사용하지 않은 메모리가 된다. -> 2KB 내부 단편화 발생

### 4. 세그멘테이션

메모리를 서로 크기가 다른 논리적인 블록 단위인 세그먼트로 분할하여 메모리를 할당하는 기법이다.

세그먼트 논리주소는 (세그먼트 번호, 변위) 두개의 주소로 지정된다. 세그먼트 테이블은 페이징 테이블과 다른데, (세그먼트 시작 물리 주소(base), 세그먼트 길이(limit))를 저장한다.

CPU에서 해당 세그먼트의 크기를 넘어서는 주소가 들어오면 인터럽트가 발생해서 해당 프로세스를 강제로 종료시킨다.

- 단점 : 서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 자유 공간들이 많은 수의 작은 조각들로 나누어져 못 쓰게 될 수도 있다.(외부 단편화)

![image](https://user-images.githubusercontent.com/38436013/128990113-f69a1e81-6d33-4b01-a907-99326fdc6871.png)

- 논리주소 (2, 100) => 물리주소 4400번지, 프로세스 메모리에 할당됨
- 논리주소 (1, 500) => 인터럽트로 인해 프로세스 강제 종료(범위를 벗어남)



# 자문 자답 QnA

### Address Binding

위에서 말한 주소 번역과 같은 의미다. CPU(프로그램이 알고 있는 주소) 주소와 실제 메모리 주소의 매핑 개념이다.



### swapping에서 swap-out 하는 경우, 프로그램 상태로 backing-store 하는가?

프로세스가 아니라 프로그램 상태로 내려보낸다.  이 경우에 프로그램은 별도의 파일시스템 영역에 그대로 남아있는 것이고 메모리 상태에 존재하고 있던 프로세스의 이미지 즉 텍스트, 데이터, 힙, 스택 등으로 구별되어 있는 이러한 상태 그대로를 하드디스크에 저장한다. 

그래서 다음에 준비 혹은 대기상태인 프로세스가 running상태로 스케줄링이 됐을 때 이 하드디스크에 저장되어 있던 데이터를 새로 적재하는 로딩과정을 거치는 것이 아니라 이 이미지만 그대로 메모리에 대해 복사해 넣기만 하면 스케줄링 되어서 CPU에서 시행될 수 있도록 한다는 것이다. 결국 이 방법은 가상메모리 기법의 핵심이 된다.



### 메모리 단편화 해결 방법을 설명해 보시오!

가상 메모리를 이용하여 내부 단편화를 해결하는 세그멘테이션, 외부 단편화를 해결하는 페이징 기법이 있다.

- Segmentation은 메모리를 서로 크기가 다른 논리적인 블록 단위인 세그먼트로 분할하여 메모리를 할당하는 기법
- Paging은 프로세스를 일정 크기인 페이지로 잘라서 메모리에 적재하는 방식



### 페이징의 장단점을 설명해 보시오!

장점 : 프로세스가 사용하는 메모리 공간을 나누기 때문에 외부 단편화를 해결할 수 있다. 

단점 : 페이지 크기보다 작은 메모리를 요청하는 경우에 내부 단편화가 발생할 수 있다.



### 출처

- https://jeongmorecord.tistory.com/97
- https://goodmilktea.tistory.com/31

- https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-12.-%EC%A3%BC%EA%B8%B0%EC%96%B5%EC%9E%A5%EC%B9%98%EA%B4%80%EB%A6%AC

- http://itnovice1.blogspot.com/2019/08/blog-post_78.html





# 1. 가상 메모리

가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법**

물리 메모리의 한계를 극복하기 위해 나온 기술, 물리 메모리보다 큰 프로세스를 수행이 가능하다.

#### 프로그램의 일부분만 메모리에 올리는 경우의 장점

- 물리 메모리 크기에 제약받지 않게 된다.
- 더 많은 프로그램을 동시에 실행할 수 있게 된다. 이에 따라 `응답시간`은 유지되고, `CPU 이용률`과 `처리율`은 높아진다.
- 스와핑에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행된다.

### 가상 메모리 

 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법**

가상적으로 주어진 주소를 가상 주소(virtual address) 또는 논리 주소(logical address) 라고 하며, 실제 메모리 상에서 유효한 주소를 물리 주소(physical address) 또는 실주소(real address)라고 한다. 가상 주소의 범위를 가상 주소 공간, 물리 주소의 범위를 물리 주소 공간이라고 한다.

### Page Fault(페이지 부재)

**CPU가 접근하려는 페이지가 메모리에 없는 경우**

페이지 폴트가 발생하면, 해당 페이지를 가상 메모리에서 찾아야한다. 이 때 운영체제가 페이지 폴트를 해결하는 과정을 요구 페이징(Demand Paging)이라고 한다.

### Demanding Paging (요구 페이징) - 페이지 부재 해결 1

**프로세스 실행에 필요한 메모리만 적재**하는 것을 말하며, 가상 메모리는 대개 페이지로 관리된다.

프로세스 내의 개별 페이지들은 `페이저(pager)`에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어 옮으로서, **사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다.**

### Page Replacement(페이지 교체) - 페이지 부재 해결 2

`요구 페이징` 에서 언급된대로 프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에, 프로세스의 동작에 필요한 페이지를 요청하는 과정에서 `page fault(페이지 부재)`가 발생하게 되면, 원하는 페이지를 보조저장장치에서 가져오게 된다. 하지만, 만약 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이뤄져야 한다.(또는, 운영체제가 프로세스를 강제 종료하는 방법이 있다.)

#### 페이지 교체 알고리즘



1. **First-In First-Out(FIFO)**

가장 먼저 page-in 한 페이지를 먼저 page-out 시킨다.

- 장점

- 적용이 쉽다

- 단점

  - 오래된 페이지에 중요한 정보가 있을 수 있다.
  - `Belady의 모순`: 페이지를 저장할 수 있는 페이지 프레임의 갯수(메모리 용량)를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재한다.

  

2. ##### Optimal Page Replacement (최적 페이지 교체)

`Belady의 모순`을 해소,  `앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체`한다.

- 장점

  - 가장 낮은 페이지 부재율을 보장한다.

- 단점

  - 구현의 어려움이 있다. 모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문이다.

  

3. ##### LRU Page Replacement ( LRU 페이지 교체)

LRU: Least-Recently-Used 

가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다.

- 대체적으로 `FIFO 알고리즘`보다 우수하고, `OPT알고리즘`보다는 그렇지 못한 모습을 보인다.



4. ##### LFU Page Replacement (LFU 페이지 교체)

LFU: Least Frequently Used

참조 횟수가 가장 적은 페이지를 교체하는 방법이다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘이다.

- 특징
  - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다가 다른 기능을 사용하게되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다.
  - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.



# 자문 자답 QnA

### 가상메모리를 우리가 왜 사용해야 할까요?

물리 메모리가 무한하지 않기 때문에 메모리를 효율적으로 사용해야 한다. 가상 메모리를 사용하는 경우 100MB 메모리 크기에서 200MB 크기의 프로세스를 수행할 수 있다. 가상메모리는 필요한 부분만 메모리에 적재하기 때문에 이런 방식이 가능하다.

### Virtual Memory에 대해서 설명하시고 사용했을 때 장점에 대해서 설명해 보시오!

일부 프로세스를 메모리에 올려서 실행 가능하도록 하는 방법이다.

물리 메모리 크기에 제약을 받지 않고, 더 많은 프로그램을 동시에 실행할 수 있다.

### Page Fault를 줄이는 방법에 대해서 설명해 보시오!

페이지 부재 발생시, 해당하는 프로세스를 불러오거나 페이지 교체를 진행한다.





### 출처

- https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC-%EC%A0%84%EB%9E%B5

- https://goodmilktea.tistory.com/36?category=816729

- https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-15.-%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC